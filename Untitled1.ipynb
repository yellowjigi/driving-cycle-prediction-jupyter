{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# ### Tensorflow time series forecasting applied to driving cycle data\n",
    "# Reference: https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Driving cycle dataset\n",
    "df_ = pd.read_csv('data/nedc.csv', names=['t (s)', 'v (km/h)'], index_col='t (s)')\n",
    "\n",
    "# Have it repeated\n",
    "df_ = pd.concat([df_, df_[1:]], ignore_index=True)\n",
    "df_.index.name = 't (s)'\n",
    "\n",
    "# Normalize the data\n",
    "# Use all the data for training (no split)\n",
    "# df = (df_ - df_.mean()) / df_.std()\n",
    "\n",
    "\n",
    "# Class for data windowing\n",
    "class WindowGenerator():\n",
    "    # 1. Indexes and offsets\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "                 df=df, label_columns=None):\n",
    "        # Store the raw data.\n",
    "        self.df = df\n",
    "\n",
    "        # Work out the label column indices.\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in enumerate(df.columns)}\n",
    "        \n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "        \n",
    "        self.total_window_size = input_width + shift\n",
    "        \n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "        \n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.label_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.label_slice]\n",
    "\n",
    "        # Store example batch of tf.data.Dataset\n",
    "        self._example = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'])\n",
    "\n",
    "    # 2. Split into inputs/labels\n",
    "    def split_window(self, features):\n",
    "        # [batch_size, window_size, features]\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.label_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:, :, self.column_indices[name]] for name in self.label_columns], axis=-1)\n",
    "\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    # 3. Plot\n",
    "    def plot(self, model=None, plot_col='v (km/h)', max_subplots=3):\n",
    "        inputs, labels = self.example\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plot_col_index = self.column_indices[plot_col] # Here we have only one input column.\n",
    "        max_n = min(max_subplots, len(inputs))\n",
    "        for n in range(max_n):\n",
    "            plt.subplot(3, 1, n + 1)\n",
    "            plt.ylabel(f'{plot_col} [normed]')\n",
    "            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                     label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "            if self.label_columns:\n",
    "                label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            else:\n",
    "                label_col_index = plot_col_index\n",
    "\n",
    "            if label_col_index is None:\n",
    "                continue\n",
    "\n",
    "            plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                        edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "\n",
    "            if model is not None:\n",
    "                predictions = model(inputs)\n",
    "                plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                            marker='X', edgecolors='k', label='Predictions',\n",
    "                            c='#ff7f0e', s=64)\n",
    "\n",
    "            if n == 0:\n",
    "                plt.legend()\n",
    "                  \n",
    "        plt.xlabel('Time [s]')\n",
    "\n",
    "    # 4. Create tf.data.Dataset\n",
    "    # Convert pandas.DataFrame to tensorflow.data.Dataset\n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=True,\n",
    "            batch_size=32)\n",
    "        ds = ds.map(self.split_window)\n",
    "        return ds\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.df)\n",
    "\n",
    "    @property\n",
    "    def example(self):\n",
    "        result = getattr(self, '_example')\n",
    "        if result is None:\n",
    "            # No example batch was found, so get one from the `.train` dataset\n",
    "            result = next(iter(self.train))\n",
    "            # And cache it for next time\n",
    "            self._example = result\n",
    "        return result\n",
    "\n",
    "\n",
    "MAX_EPOCHS = 32\n",
    "\n",
    "\n",
    "def compile_and_fit(model, window, patience=2):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                      patience=patience,\n",
    "                                                      mode='min')\n",
    "\n",
    "    model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                  optimizer=tf.optimizers.Adam(),\n",
    "                  metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                        validation_data=window.train,\n",
    "                        callbacks=[early_stopping])\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "# Multi-step prediction models\n",
    "\n",
    "OUT_STEPS = 32\n",
    "multi_window = WindowGenerator(input_width=32,\n",
    "                               label_width=OUT_STEPS,\n",
    "                               shift=OUT_STEPS)\n",
    "\n",
    "# RNN\n",
    "multi_lstm_model = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, lstm_units]\n",
    "    # Adding more `lstm_units` just overfits more quickly.\n",
    "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "    # Shape => [batch, out_steps * features]\n",
    "    tf.keras.layers.Dense(OUT_STEPS, kernel_initializer=tf.initializers.zeros),\n",
    "    # Shape => [batch, out_steps, features]\n",
    "    tf.keras.layers.Reshape([OUT_STEPS, 1])])\n",
    "\n",
    "history = compile_and_fit(multi_lstm_model, multi_window)\n",
    "\n",
    "multi_performance = {'LSTM': multi_lstm_model.evaluate(multi_window.train)}\n",
    "\n",
    "multi_window.plot(multi_lstm_model)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
